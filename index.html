<!DOCTYPE html>

<html>
<head>
  <meta charset="utf-8" />
  <title>Mahi Rahimi &mdash; Home</title>
  <link rel="stylesheet" href="master.css" />
  <link href="https://fonts.googleapis.com/css?family=Roboto+Slab:300,400,700" rel="stylesheet">

  <script>
      function unhide(divID) {
          var item = document.getElementById(divID);
          if (item) {
              item.className=(item.className=='hidden')?'unhidden':'hidden';
          }
      }
  </script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-8Z6H6C3QBH"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-8Z6H6C3QBH');
</script>

    <meta name="author" content="Mahi Rahimi">
    <meta name="keywords" content="Mahi Rahimi KAIST Moon Multi-Agent Game-Theory">
    <meta name="robots" content="index,follow">
    <meta name="description" content="Homepage of Mahi Rahimi KAIST MoonLab">

</head>

<body>
<div class="wrapper">

  <div class="posts-wrapper">
    <div class="post">
      <img src='full.jpg' style="float:right; width:280px"/>

      <h1>Mahi Rahimi</h1>

      <h2>
          mahi@kaist.ac.kr |
          <a style="font-size: 0.95em; font-weight:700" href="https://twitter.com/MahiRahimi" target="_blank">Twitter</a> |
          <a style="font-size: 0.95em; font-weight:700" href="https://www.instagram.com/__.mahi.__" target="_blank">Instagram</a> |
          <a style="font-size: 0.95em; font-weight:700" href="https://scholar.google.com/citations?user=O-KLBfAAAAAJ&hl=en" target="_blank"> Scholar </a> |
          <a style="font-size: 0.95em; font-weight:700" href="https://www.github.com/mahi97" target="_blank">GitHub</a> |
          <a style="font-size: 0.95em; font-weight:700" href="Academic_CV.pdf" target="_blank">CV</a> |
          <a style="font-size: 0.95em; font-weight:700" href="https://mahi97.github.io/mahi-log" target="_blank">Blog</a>  </h2>
      <br>
      <br>

            <br> <br>
            <p>Hi! I am a first-year PhD student at KAIST advised by <a href="http://comstolab.kaist.ac.kr/people.html" target="_blank">JeaKyun Moon</a>. I work on Machine Learning and Multi-Agent Reinforcment Learning as part of <a href="http://comstolab.kaist.ac.kr" target="_blank">MoonLab</a>.
            <br> <br>

	    Before this, I did my undergrad at the Tehran Polytechnic, where I worked with <a href="https://scholar.google.com/citations?user=Q7F-doQAAAAJ&hl=en" target="_blank">MohammadAzam Khosravi</a> and <a href="https://scholar.google.com/citations?user=080Y_lUAAAAJ&hl=en" target="_blank">MohammadMehdi Ebadzadeh</a> on RoboCup SSL platform and multi-agent learning. I start working at the <a href="https://brtel.co/" target="_blank">BRTel Co.</a> since 2019 on Bussiness Intelligence and Data Mining Solutions for <a href="https://mci.ir/" target="_blank"> MCI Telecommuncation</a>.
            <br><br>

            <h3 style="margin-bottom:0.75em;">News</h3>

            <p>
              <b>[2020]  I Joind MoonLab @ KAIST.</b> <br>
              <b>[2020]  I Complete my B.Sc in Software Eng.</b> <br>
              <b>[2019]  I am honored to join AI WorldCup as Advisory Board.</b> <br>
              <b>[2019]  I am honored to join FIRA WorldCup as Simulation League Co-Chair.</b> <br>
              <b>[2019]  I am honored to get EurAI Travel Grant for ACAI Summer School.</b> <br>
              <b>[2018]  We got into top 14 finalist of Tianchi Bigdata competition.</b> <br>
              <b>[2018]  We won 3rd Place @ FIRACup Simulation - Taichung, Taiwan.</b> <br>
              <b>[2018]  Our Paper got accepted on Journal of Open Source Software.</b> <br>
              <b>[2017]  We won 4th Place @ RoboCup SSL, Nagoya - Japan.</b> <br>
              <b>[2016]  I co-organized the Robotic Summer School @ AUT.</b> <br>
              <b>[2015]  I Joind AUT as Talented Student.</b> <br>
             </p>


            <h3 style="margin-bottom:0.75em;">Research Focus</h3>

            <p><b>Multi-Agent Reinforcment Learning</b> I study how multi-agent systems works and how we can improve the performance of system by using DeepRL with respect to underling game theoritical analysis.</p>

            <p><b>Meta Learning and Reasoning</b> Meta learning aims to learn a general strategy to learn new tasks. We focus on theoretical analysis on meta learning and developing meta learning algorithm for high speed/adaptive learning. We propose a novel meta learning algorithm using neural network augmented with task-adaptive projection for few-shot learning.</p>

            <p><b>Distributed Learning</b> Distributed learning enables to train a large-scale learning model with massive dataset. We investigate ways of speeding up and securing distributed learning in various scenarios. We propose coding schemes specifically geared to the tiered and broadcast nature of wireless edge networks.
    </p>
          <br>
      </div>
  </div>

  <div class="posts-wrapper" style="clear:both">
    <h3 style="margin-bottom:0.75em;">publications</h3>
    </i>
    <p>

    <ul class="pubs">

    <li>
          <a href="https://joss.theoj.org/papers/10.21105/joss.00676.pdf" target="_blank" style="color:black;font-size:1.0em">
          OPEM: Open source PEM cell simulation tool</a><br>
          Sepand Haghighi, Kasra Askari, Sarmin Hamidi, <b>Mohammad Mahdi Rahimi</b><br>
          <i>JOSS 2018</i><br>
          <a href="javascript:unhide('haghighi2018opemtldr');">TLDR</a> |
          <!-- <a href="http://mahi97.github.io/mahi-log" target="_blank">Blog</a> | -->
          <!-- <a href="https://twitter.com/MahiRahimi" target="_blank">Twitter</a> |  -->
          <a href="https://joss.theoj.org/papers/10.21105/joss.00676.pdf" target="_blank">Paper</a> |
          <a href="https://github.com/ECSIM/OPEM" target="_blank">Code</a> |
          <a href="javascript:unhide('haghighi2018opem');">Citation</a>
          <div id="haghighi2018opemtldr" class="hidden">
            <b>TLDR:</b>
             The sun and wind as renewable energy sources are attracting more regard as alternative energy sources. In addition to the decreasing fuel sources, pollution and global warming are important problems. Fuel cells are a beneficial energy technology that generates electric energy through the reaction between the fuel sources rich in hydrogen and oxygen. In comparsion with combustion engines, fuel cells have many advantages, such as high efficiency and low emissions. Furthermore the by-products of fuel cells are heat and water. Proton exchange membrane fuel cells (PEMFCs) have attracted much interests recently. PEM fuel cells are Pollution-Free high-efficiency power sources for urban vehicles that recently corporate by legislative initiatives.
            <br>
          </div>
        <div id="haghighi2018opem" class="hidden">
          <pre>@article{haghighi2018opem,
              title={OPEM: Open source PEM cell simulation tool},
              author={Haghighi, Sepand and Askari, Kasra and Hamidi, Sarmin and Rahimi, Mohammad Mahdi},
              journal={Journal of Open Source Software},
              volume={3},
              number={27},
              pages={676},
              year={2018}}
           </pre>
         </div>
    </li>

    <li>
          <a href="https://www.semanticscholar.org/paper/PARSIAN-2019-Extended-Team-Description-Paper-Behzad-Daneshmand/8ad8463f1a042f6192ae39bd8feb6b252283519b?p2df" target="_blank" style="color:black;font-size:1.0em">
          PARSIAN 2019 Extended Team Description Paper</a><br>
          Kian Behzad, et al. <br>
          <i>RoboCup 2019</i><br>
          <a href="javascript:unhide('behzad2019parsiantldr');">TLDR</a> |
          <!-- <a href="http://mahi97.github.io/mahi-log" target="_blank">Blog</a> | -->
          <!-- <a href="https://twitter.com/MahiRahimi" target="_blank">Twitter</a> |  -->
          <a href="https://ssl.robocup.org/wp-content/uploads/2019/03/2019_ETDP_Parsian.pdf" target="_blank">Paper</a> |
          <!-- <a href="https://github.com/ECSIM/OPEM" target="_blank">Code</a> | -->
          <a href="javascript:unhide('behzad2019parsian');">Citation</a>
          <div id="behzad2019parsiantldr" class="hidden">
            <b>TLDR:</b>
             This paper illustrates detailed mechanical, electronics, control, and software improvements made by Parsian Small Size Soccer team since last year. The notable mechanical change is improving the dribbler system to receive and control the ball more proficiently. Likewise, some improvements have been made in electronic to cooperate more efficiently with the software system. We used computational geometry algorithm to improve the path planning. Moreover, providing the inverse-model of the robots’ kinematics was profitable to correct the robot motion. New developments in the log analyzer have also been provided. Lastly, an attempt to learn the opponent defense strategies have been explained.
             <br>
          </div>
        <div id="behzad2019parsian" class="hidden">
          <pre>@article{behzad2019parsian,
                title={PARSIAN 2019 Extended Team Description Paper},
                author={Behzad, Kian and Daneshmand, Elham and Moradi, Nadia and
                  Hajmohammadi,Mahdi and Onidin, Mohammad Reza Kolani and
                  Gharib, Yasamin Alizadeh and Pirmoradi, Atiyeh and
                  Rahimi, Mohammad Mahdi and Shirazi, Mohammad Mahdi and Khosravi, Mohammad Azam}
              }
           </pre>
         </div>
    </li>

    <li>
          <a href="https://ssl.robocup.org/wp-content/uploads/2019/01/2018_ETDP_Parsian.pdf" target="_blank" style="color:black;font-size:1.0em">
          PARSIAN 2018 Extended Team Description Paper</a><br>
          <b>Mohammad Mahdi Rahimi</b>, et al.<br>
          <i>RoboCup 2018</i><br>
          <a href="javascript:unhide('Rahimi2018PARSIAN2Etldr');">TLDR</a> |
          <!-- <a href="http://mahi97.github.io/mahi-log" target="_blank">Blog</a> | -->
          <!-- <a href="https://twitter.com/MahiRahimi" target="_blank">Twitter</a> |  -->
          <a href="https://ssl.robocup.org/wp-content/uploads/2019/01/2018_ETDP_Parsian.pdf" target="_blank">Paper</a> |
          <!-- <a href="https://github.com/ECSIM/OPEM" target="_blank">Code</a> | -->
          <a href="javascript:unhide('Rahimi2018PARSIAN2E');">Citation</a>
          <div id="Rahimi2018PARSIAN2Etldr" class="hidden">
            <b>TLDR:</b>
             This paper presents Parsian’s hardware elaboration, the soft-ware architecture and all improvements that have been made since lastyear,  including  useful  innovations  in  hardware,  e.g.  new  ball  detectionsensor, debugger module and robot’s fault recovery. Noteworthy enhance-ments in software such as micro-service architecture by ROS, open loopmotion correction, motion profiler and new obstacle avoidance strategyare described.
             <br>
          </div>
        <div id="Rahimi2018PARSIAN2E" class="hidden">
          <pre>@inproceedings{Rahimi2018PARSIAN2E,
                title={PARSIAN 2018 Extended Team Description Paper},
                author={M. Rahimi and M. M. Shirazi and Maziar Arfaee and Mohammad Amin Najaf Gholian
                  and A. H. Zamani and H. Hosseini and Fateme Hashemi Chaleshtori and N. Moradi and
                  Atousa Ahsani and M. Jafari and A. Zahedi and Parsa Abdollahi and A. Zolanvari
                  and M. Azam and Khosravi},
                year={2018}
              }
           </pre>
         </div>
    </li>

    <li>
          <a href="https://www.semanticscholar.org/paper/PARSIAN-2017-Extended-Team-Description-Paper-Rahimi-Shirazi/328ae68847ac7a5f321003110d9495342720f6fa#citing-papers" target="_blank" style="color:black;font-size:1.0em">
          PARSIAN 2017 Extended Team Description Paper</a><br>
          <b>Mohammad Mahdi Rahimi</b>, et al.<br>
          <i>RoboCup 2017</i><br>
          <a href="javascript:unhide('Rahimi2017PARSIAN2Etldr');">TLDR</a> |
          <!-- <a href="http://mahi97.github.io/mahi-log" target="_blank">Blog</a> | -->
          <!-- <a href="https://twitter.com/MahiRahimi" target="_blank">Twitter</a> |  -->
          <a href="https://ssl.robocup.org/wp-content/uploads/2019/03/2019_ETDP_Parsian.pdf" target="_blank">Paper</a> |
          <!-- <a href="https://github.com/ECSIM/OPEM" target="_blank">Code</a> | -->
          <a href="javascript:unhide('Rahimi2017PARSIAN2E');">Citation</a>
          <div id="Rahimi2017PARSIAN2Etldr" class="hidden">
            <b>TLDR:</b>
             In this paper detailed description of Parsian robots’ hardware improvement, as well as the software architecture with focus on new improvements that have been made since last year, is represented. Improvements and developments that seemed innovative and useful in hardware like fault detection, two way communication and dribbler system and also improvements in software such as pass and interception skills’ behavior, adaptive attack strategy for regular game and reactive offense and defense for free kicks will be discussed in detail.
             <br>
          </div>
        <div id="Rahimi2017PARSIAN2E" class="hidden">
          <pre>@inproceedings{Rahimi2017PARSIAN2E,
                title={PARSIAN 2017 Extended Team Description Paper},
                author={M. Rahimi and M. M. Shirazi and Maziar Arfaee and Mohammad Amin Najaf Gholian and
                  A. H. Zamani and H. Hosseini and Fateme Hashemi Chaleshtori and
                  N. Moradi and Atousa Ahsani and M. Jafari and A. Zahedi and
                  Parsa Abdollahi and A. Zolanvari and M. Azam and Khosravi}
                year={2017}
              }
           </pre>
         </div>
    </li>

    <li>
          <a href="https://ssl.robocup.org/wp-content/uploads/2019/01/2016_ETDP_Parsian.pdf" target="_blank" style="color:black;font-size:1.0em">
          PARSIAN 2016 Extended Team Description Paper</a><br>
          <b>Mohammad Mahdi Rahimi</b>, et al.<br>
          <i>RoboCup 2016</i><br>
          <a href="javascript:unhide('Rahimi2017PARSIAN2Etldr');">TLDR</a> |
          <!-- <a href="http://mahi97.github.io/mahi-log" target="_blank">Blog</a> | -->
          <!-- <a href="https://twitter.com/MahiRahimi" target="_blank">Twitter</a> |  -->
          <a href="https://ssl.robocup.org/wp-content/uploads/2019/01/2016_ETDP_Parsian.pdf" target="_blank">Paper</a> |
          <!-- <a href="https://github.com/ECSIM/OPEM" target="_blank">Code</a> | -->
          <a href="javascript:unhide('Rahimi2017PARSIAN2E');">Citation</a>
          <div id="Rahimi2017PARSIAN2Etldr" class="hidden">
            <b>TLDR:</b>
             The Parsianteam placed top eight teams in the Small Size League  of RoboCup 2015. In this paper, we  present our robots’ current design in mechanical, electrical and the team’s recent work on the  offensive  and defensive  tactics,  low  level  skills.  Among  the offensive tactics, we introduce new features in our visual planner and that in both play on and play off then We present a change in defense mark  system  that  increase  reliability  and  robot  ball-manipulation skill that keep ball till asuitable situation occurs. Finally, we describe improvements  to the  ball and robots state estimation  algorithms  by profiling robots and field.
             <br>
          </div>
        <div id="Rahimi2017PARSIAN2E" class="hidden">
          <pre>@article{zolanvarimohammad,
                  title={PARSIAN 2016 Extended Team Description Paper},
                  author={Mohammad Mahdi Rahimi, Mohammad Mahdi Shirazi, Seyede Parisa Dajkhosh,
                    Alireza Zolanvari, Maziar Arfaee, Hamidreza Kazemi Khoshkijari,
                    Amirhossein Abbasi Fashami, Alireza Saeidi Shahrivar and
                    Mohammad Azam Khosravi.}
                }
           </pre>
         </div>
    </li>

    <li>
          <a href="https://ssl.robocup.org/wp-content/uploads/2019/01/2015_TDP_Parsian.pdf" target="_blank" style="color:black;font-size:1.0em">
          PARSIAN 2015 Extended Team Description Paper</a><br>
          Alireza Zolanvari, et al.<br>
          <i>RoboCup 2015</i><br>
          <a href="javascript:unhide('naderialirezatldr');">TLDR</a> |
          <!-- <a href="http://mahi97.github.io/mahi-log" target="_blank">Blog</a> | -->
          <!-- <a href="https://twitter.com/MahiRahimi" target="_blank">Twitter</a> |  -->
          <a href="https://ssl.robocup.org/wp-content/uploads/2019/01/2015_TDP_Parsian.pdf" target="_blank">Paper</a> |
          <!-- <a href="https://github.com/ECSIM/OPEM" target="_blank">Code</a> | -->
          <a href="javascript:unhide('naderialireza');">Citation</a>
          <div id="naderialirezatldr" class="hidden">
            <b>TLDR:</b>
             This is the team description paper of the Small Size Soccer Robot team “PARSIAN” for entering the RoboCup 2015 competitions in China. In this  paper  we  will  represent  our  robots’  current  design  in  mechanical, electrical,  control  and  software  parts.  Improvements  and  developments  like new mechanical design, control system, visual plannerand enhancements in predefined plays.
             <br>
          </div>
        <div id="naderialireza" class="hidden">
          <pre>@article{naderialireza,
                title={PARSIAN 2015 Extended Team Description Paper},
                author={Alireza Zolanvari, Mohammad Mahdi Shirazi, Seyede Parisa Dajkhosh,
                Amir Mohammad Naderi, Maziar Arfaee, Mohammad Behbooei, Hamidreza Kazemi Khoshkijari,
                Erfan Tazimi, Mohammad Mahdi Rahimi and Alireza Saeidi Shahrivar.}
              }
           </pre>
         </div>
    </li>

    <!-- <li>
          <a href="https://arxiv.org/abs/2002.11794" target="_blank" style="color:black;font-size:1.0em">
          Train Large, Then Compress: Rethinking Model Size for Efficient Training and Inference of Transformers</a><br>
          Zhuohan Li*, Eric Wallace*, Sheng Shen*, Kevin Lin*, Kurt Keutzer, Dan Klein, and Joseph E. Gonzalez<br>
          <i>ICML 2020</i><br>
          <a href="javascript:unhide('efficient20tldr');">TLDR</a> | <a href="https://bair.berkeley.edu/blog/2020/03/05/compress/" target="_blank">Blog</a> | <a href="https://twitter.com/Eric_Wallace_/status/1235616760595791872" target="_blank">Twitter</a> | <a href="https://arxiv.org/abs/2002.11794" target="_blank">Paper</a> | <a href="slides_and_posters/train_large.pdf" target="_blank">Slides</a> | <a href="javascript:unhide('efficient20');">Citation</a>
          <div id="efficient20tldr" class="hidden"><b>TLDR:</b> We show that <i>increasing</i> model size actually speeds up training and inference for Transformer models. The key idea is to use a very large model, but, perform very few epochs and apply heavy compression.<br></div>
            <div id="efficient20" class="hidden">
            <pre>@inproceedings{Li2020Efficient,
  Author = {Zhuohan Li and Eric Wallace and Sheng Shen and Kevin Lin and Kurt Keutzer and Dan Klein and Joseph E. Gonzalez},
  Booktitle = {International Conference on Machine Learning},
  Year = {2020},
  Title = {Train Large, Then Compress: Rethinking Model Size for Efficient Training and Inference of Transformers}}
             </pre>
             </div>
    </li>

    <li>
    <a href="https://arxiv.org/abs/2004.06100" target="_blank" style="color:black;font-size:1.0em">Pretrained Transformers Improve Out-of-Distribution Robustness</a><br>
    Dan Hendrycks*, Xiaoyuan Liu*, Eric Wallace, Adam Dziedzic, Rishabh Krishnan, and Dawn Song<br>
    <i>ACL 2020</i><br>
    <a href="javascript:unhide('robust20tldr');">TLDR</a> | <a href="https://arxiv.org/abs/2004.06100" target="_blank">Paper</a> | <a href="https://twitter.com/Eric_Wallace_/status/1250507707674578944" target="_blank">Twitter</a> | <a href="https://github.com/camelop/NLP-Robustness" target="_blank">Code</a> | <a href="slides_and_posters/ood_robustness.pdf" target="_blank">Slides</a> | <a href="javascript:unhide('robust20');">Citation</a>
    <div id="robust20tldr" class="hidden"><b>TLDR:</b> How does pretraining affect <i>out-of-distribution</i> robustness? We create an OOD benchmark and use it to show that pretraining substantially improves OOD accuracy and detection rates.<br></div>
  <div id="robust20" class="hidden">
  <pre>@inproceedings{hendrycks2020pretrained,
    Author = {Dan Hendrycks and Xiaoyuan Liu and Eric Wallace and Adam Dziedzic and Rishabh Krishnan and Dawn Song},
    Booktitle = {Association for Computational Linguistics},
    Year = {2020},
    Title = {Pretrained Transformers Improve Out-of-Distribution Robustness}}
   </pre>
   </div>
   </li>



        <li>
                <a href="https://arxiv.org/abs/1908.07125" target="_blank" style="color:black;font-size:1.0em">Universal Adversarial Triggers for Attacking and Analyzing NLP</a><br>
                Eric Wallace, Shi Feng, Nikhil Kandpal, Matt Gardner, and Sameer Singh<br>
                <i>EMNLP 2019</i><br>
          <a href="javascript:unhide('triggers19tldr');">TLDR</a> | <a href="https://vimeo.com/396789889" target="_blank">Video</a> | <a href="http://ericswallace.com/triggers" target="_blank">Blog</a> | <a href="https://twitter.com/Eric_Wallace_/status/1168907518623571974" target="_blank">Twitter</a> | <a href="https://arxiv.org/abs/1908.07125" target="_blank">Paper</a> | <a href="https://github.com/Eric-Wallace/universal-triggers" target="_blank">Code</a> | <a href="slides_and_posters/Universal_Adversarial_Triggers.pdf" target="_blank">Slides</a> | <a href="javascript:unhide('triggers19');">Citation</a>
          <div id="triggers19tldr" class="hidden"><b>TLDR:</b> We create phrases that cause a model to produce a specific prediction when concatenated to <i>any</i> input. Triggers reveal egregious and insightful errors for text classification, reading comprehension, and text generation.<br> </div>
                <div id="triggers19" class="hidden">
                    <pre>@inproceedings{Wallace2019Triggers,
    Author = {Eric Wallace and Shi Feng and Nikhil Kandpal and Matt Gardner and Sameer Singh},
    Booktitle = {Empirical Methods in Natural Language Processing},
    Year = {2019},
    Title = {Universal Adversarial Triggers for Attacking and Analyzing {NLP}}}
                    </pre>
                </div>
            </li>
            <li>
                <a href="https://arxiv.org/abs/1909.07940" target="_blank" style="color:black;font-size:1.0em">Do NLP Models Know Numbers? Probing Numeracy in Embeddings</a><br>
                Eric Wallace, Yizhong Wang, Sujian Li, Sameer Singh, and Matt Gardner<br>
                <i>EMNLP 2019</i><br>
                 <a href="javascript:unhide('numeracy19tldr');">TLDR</a> | <a href="https://twitter.com/Eric_Wallace_/status/1174360279624192000" target="_blank">Twitter</a> | <a href="https://arxiv.org/abs/1909.07940" target="_blank">Paper</a> | <a href="https://github.com/Eric-Wallace/numeracy" target="_blank">Code</a> | <a href="slides_and_posters/NumeracyPoster.pdf" target="_blank">Poster</a> | <a href="javascript:unhide('numeracy19');">Citation</a>
                 <div id="numeracy19tldr" class="hidden"><b>TLDR:</b> We show that pre-trained word embeddings (e.g., BERT, word2vec, ELMo, GloVe) capture number magnitude and order, e.g., they know that "74" is smaller than "eighty-two". This facilitates basic numerical reasoning tasks. <br></div>
                <div id="numeracy19" class="hidden">
                    <pre>@inproceedings{Wallace2019Numeracy,
    Author = {Eric Wallace and Yizhong Wang and Sujian Li and Sameer Singh and Matt Gardner},
    Booktitle = {Empirical Methods in Natural Language Processing},
    Year = {2019},
    Title = {Do {NLP} Models Know Numbers? Probing Numeracy in Embeddings}}
                    </pre>
                </div>
            </li>

            <li>
                <a href="https://arxiv.org/abs/1909.09251" target="_blank" style="color:black;font-size:1.0em">AllenNLP Interpret: A Framework for Explaining Predictions of NLP Models</a><br>
                Eric Wallace, Jens Tuyls, Junlin Wang, Sanjay Subramanian, Matt Gardner, and Sameer Singh<br>
          <i>Demo at EMNLP 2019</i> &nbsp;&nbsp;&nbsp; <b><i>Best Demo Award</i></b><br>
                <a href="javascript:unhide('interpret19tldr');">TLDR</a> | <a href="https://allennlp.org/interpret" target="_blank">Landing Page</a> | <a href="https://twitter.com/Eric_Wallace_/status/1176886627852898309" target="_blank">Twitter</a> | <a href="https://demo.allennlp.org/reading-comprehension" target="_blank">Demo</a> | <a href="https://arxiv.org/abs/1909.09251" target="_blank">Paper</a> | <a href="slides_and_posters/InterpretPoster.pdf" target="_blank">Poster</a> | <a href="javascript:unhide('interpret19');">Citation</a>
                <div id="interpret19tldr" class="hidden"><b>TLDR:</b> An open-source toolkit built on top of AllenNLP that makes it easy to interpret NLP models.<br> </div>
                <div id="interpret19" class="hidden">
                    <pre>@inproceedings{Wallace2019AllenNLP,
    Author = {Eric Wallace and Jens Tuyls and Junlin Wang and Sanjay Subramanian and Matt Gardner and Sameer Singh},
    Booktitle = {Empirical Methods in Natural Language Processing},
    Year = {2019},
    Title = {{AllenNLP Interpret}: A Framework for Explaining Predictions of {NLP} Models}}
                    </pre>
                </div>
            </li>

      <li>
                <a href="https://arxiv.org/abs/1905.05778" target="_blank" style="color:black;font-size:1.0em">Misleading Failures of Partial-input Baselines</a><br>
                Shi Feng, Eric Wallace, and Jordan Boyd-Graber<br>
                <i>ACL 2019</i><br>
                <a href="javascript:unhide('misleading19tldr');">TLDR</a> | <a href="https://arxiv.org/abs/1905.05778" target="_blank">Paper</a> | <a href="slides_and_posters/Misleading_Poster.pdf" target="_blank">Poster</a> | <a href="javascript:unhide('misleading19');">Citation</a>
                <div id="misleading19tldr" class="hidden"><b>TLDR:</b> A common technique for analyzing datasets is partial-input baselines (e.g., question-only or hypothesis-only models). We show how these baselines can be misleading, and solve "hard" SNLI examples using cheap tricks.<br></div>
                <div id="misleading19" class="hidden">
          <pre>@inproceedings{Feng2019Misleading,
    Author = {Shi Feng and Eric Wallace and Jordan Boyd-Graber},
    Booktitle = {Association for Computational Linguistics},
    Year = {2019},
    Title = {Misleading Failures of Partial-input Baselines}}
                  </pre>
                </div>
            </li>

            <li>
                <a href="http://arxiv.org/abs/1906.02900" target="_blank" style="color:black;font-size:1.0em">Compositional Questions Do Not Necessitate Multi-hop Reasoning</a><br>
                Sewon Min*, Eric Wallace*, Sameer Singh, Matt Gardner, Hannaneh Hajishirzi, and Luke Zettlemoyer<br>
                <i>ACL 2019</i><br>
        <a href="javascript:unhide('multihop19tldr');">TLDR</a> | <a href="https://arxiv.org/abs/1906.02900" target="_blank">Paper</a> | <a href="slides_and_posters/Compositional_Slides.pdf" target="_blank">Slides</a> | <a href="https://github.com/shmsw25/single-hop-rc" target="_blank">Code</a> | <a href="javascript:unhide('multihop19');">Citation</a>
        <div id="multihop19tldr" class="hidden"><b>TLDR:</b> We argue that constructing multi-hop QA datasets is non-trivial, and that existing datasets are simpler than expected. For instance, single-hop models can solve most of HotpotQA due to weak distractor paragraphs.<br></div>
                <div id="multihop19" class="hidden">
          <pre>@inproceedings{Min2019Multihop,
    Author = {Sewon Min and Eric Wallace and Sameer Singh and Matt Gardner and Hannaneh Hajishirzi and Luke Zettlemoyer},
    Booktitle = {Association for Computational Linguistics},
    Year = {2019},
    Title = {Compositional Questions Do Not Necessitate Multi-hop Reasoning}}
                  </pre>
                </div>
            </li>
            <li>
                <a href="https://arxiv.org/abs/1809.02701" target="_blank" style="color:black;font-size:1.0em">Trick Me If You Can: Human-in-the-loop Generation of Adversarial Examples for Question Answering</a><br>
                Eric Wallace, Pedro Rodriguez, Shi Feng, Ikuya Yamada, and Jordan Boyd-Graber<br>
                <i>TACL 2019</i><br>
                <a href="javascript:unhide('trick19tldr');">TLDR</a> | <a href="https://arxiv.org/abs/1809.02701" target="_blank">Paper</a> | <a href="https://github.com/Eric-Wallace/trickme-interface" target="_blank">Code</a> | <a href="slides_and_posters/TrickMe_Poster.pdf" target="_blank">Poster</a> | <a href="javascript:unhide('trick19');">Citation</a>
                <div id="trick19tldr" class="hidden"><b>TLDR:</b> We use a human-in-the-loop approach for generating adversarial examples in NLP. We display model intepretations and predictions in a UI, which enables collaborative + interactive attacks on question answering systems .<br></div>
                <div id="trick19" class="hidden">
          <pre>@inproceedings{Wallace2019Trick,
    Author = {Eric Wallace and Pedro Rodriguez and Shi Feng and Ikuya Yamada and Jordan Boyd-Graber},
    Booktitle = {Transactions of the Association for Computational Linguistics},
    Year = {2019},
    Title = {Trick Me If You Can: Human-in-the-loop Generation of Adversarial Examples for Question Answering}}
                  </pre>
                </div>
            </li>

     <li>
                <a href="https://arxiv.org/abs/1804.07781" target="_blank" style="color:black;font-size:1.0em">Pathologies of Neural Models Make Interpretations Difficult</a><br>
                Shi Feng, Eric Wallace, Alvin Grissom II, Mohit Iyyer, Pedro Rodriguez, Jordan Boyd-Graber<br>
                <i>EMNLP 2018</i><br>
                <a href="javascript:unhide('pathological18tldr');">TLDR</a> | <a href="https://vimeo.com/306158589" target="_blank">Video</a> | <a href="https://arxiv.org/abs/1804.07781" target="_blank">Paper</a> |
                <a href="slides_and_posters/pathologies_slides.pdf" target="_blank">Slides</a> | <a href="https://github.com/allenai/allennlp/blob/master/allennlp/interpret/attackers/input_reduction.py" target="_blank">Code</a> | <a href="javascript:unhide('pathological18');">Citation</a>
                <div id="pathological18tldr" class="hidden"><b>TLDR:</b> Saliency maps are a popular interpretation technique. We show that certain pathological behavior present in neural models (namely prediction overconfidence) can negatively impact these interpretations.<br> </div>
                <div id="pathological18" class="hidden">
                    <pre>@inproceedings{Feng2018Pathological,
    Author = {Shi Feng and Eric Wallace and Alvin Grissom II and Mohit Iyyer and Pedro Rodriguez and Jordan Boyd-Graber},
    Booktitle = {Empirical Methods in Natural Language Processing},
    Year = {2018},
    Title = {Pathologies of Neural Models Make Interpretations Difficult}}
                  </pre>
                </div>
            </li> -->
        </ul>
    </p>

</div>
</div>

<table width="100%" cellspacing="0" cellpadding="20" border="0" align="center">
      <tbody><tr>
        <td>
        <br>
        <p align="right"><font size="2">
          <a href="https://www.ericswallace.com/">This guy makes a nice webpage.</a>
          </font>
        </p>
        </td>
      </tr>
  </tbody></table>

</body>
</html>
